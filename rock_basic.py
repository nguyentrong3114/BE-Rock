import numpy as np
from sklearn.metrics import pairwise_distances
from sklearn.preprocessing import Binarizer

class RockClustering:
    def __init__(self, k=2, theta=0.5, metric='jaccard', min_goodness=0.001,
                 max_cluster_size_ratio=0.8, sample_ratio=0.2, verbose=False):
        # Sá»‘ cá»¥m mong muá»‘n
        self.k = k
        # NgÆ°á»¡ng similarity (theta) Ä‘á»ƒ xÃ¡c Ä‘á»‹nh neighbor
        self.theta = theta
        # Loáº¡i similarity metric (máº·c Ä‘á»‹nh: jaccard)
        self.metric = metric
        # NgÆ°á»¡ng tá»‘i thiá»ƒu cho goodness Ä‘á»ƒ gá»™p cá»¥m
        self.min_goodness = min_goodness
        # Tá»‰ lá»‡ tá»‘i Ä‘a cho kÃ­ch thÆ°á»›c cá»¥m khi gá»™p
        self.max_cluster_size_ratio = max_cluster_size_ratio
        # Tá»‰ lá»‡ sampling trÃªn toÃ n bá»™ dá»¯ liá»‡u
        self.sample_ratio = sample_ratio
        # Báº­t/táº¯t log thÃ´ng tin
        self.verbose = verbose

    def preprocess(self, X):
        # Náº¿u dÃ¹ng jaccard, cáº§n Ä‘áº£m báº£o dá»¯ liá»‡u nhá»‹ phÃ¢n (0/1)
        if self.metric == 'jaccard':
            if not np.all(np.isin(np.unique(X), [0, 1])):
                if self.verbose:
                    print("ðŸ”§ Data is not binary. Applying Binarizer (threshold=0).")
                X = Binarizer(threshold=0.0).fit_transform(X)
        return X

    def _similarity(self, X):
        # TÃ­nh similarity matrix (1 - khoáº£ng cÃ¡ch) giá»¯a cÃ¡c Ä‘iá»ƒm
        S = 1 - pairwise_distances(X, metric=self.metric)
        # LÃ m Ä‘á»‘i xá»©ng ma tráº­n Ä‘á»ƒ trÃ¡nh sai sá»‘
        return (S + S.T) / 2

    def _calculate_goodness(self, ci, cj, link_matrix):
        # TÃ­nh sá»‘ lÆ°á»£ng link (neighbor chung) giá»¯a hai cá»¥m ci vÃ  cj
        num_links = link_matrix[np.ix_(ci, cj)].sum()
        size_ci = len(ci)
        size_cj = len(cj)
        # TÃ­nh tá»‰ lá»‡ kÃ­ch thÆ°á»›c giá»¯a cá»¥m nhá» vÃ  cá»¥m lá»›n
        size_ratio = min(size_ci, size_cj) / max(size_ci, size_cj)
        # TÃ­nh máº«u sá»‘ theo cÃ´ng thá»©c (ni + nj)^(1 + 2Î¸)
        denom = (size_ci + size_cj) ** (1 + 2 * self.theta)
        if denom == 0:
            return -np.inf  # TrÃ¡nh chia 0
        # CÃ´ng thá»©c goodness, cÃ³ nhÃ¢n thÃªm size_ratio Ä‘á»ƒ trÃ¡nh gá»™p lá»‡ch
        return (num_links / denom) * size_ratio

    def _assign_remaining_points(self, X_all, sample_idx, clusters_sample, labels_sample):
        # TÃ¬m cÃ¡c Ä‘iá»ƒm chÆ°a náº±m trong sample
        remaining_idx = np.setdiff1d(np.arange(X_all.shape[0]), sample_idx)
        X_remaining = X_all[remaining_idx]
        # Khá»Ÿi táº¡o máº£ng nhÃ£n cho toÃ n bá»™ dá»¯ liá»‡u
        labels_all = np.full(X_all.shape[0], -1)

        # GÃ¡n nhÃ£n cho sample
        for idx, point_idx in enumerate(sample_idx):
            labels_all[point_idx] = labels_sample[idx]

        # GÃ¡n nhÃ£n cho cÃ¡c Ä‘iá»ƒm cÃ²n láº¡i
        for idx, point in zip(remaining_idx, X_remaining):
            max_sim = -1
            best_cluster = -1
            # TÃ­nh similarity trung bÃ¬nh vá»›i tá»«ng cá»¥m
            for cluster_id in np.unique(labels_sample):
                cluster_points = X_all[sample_idx][labels_sample == cluster_id]
                sims = 1 - pairwise_distances(cluster_points, point.reshape(1, -1), metric=self.metric)
                avg_sim = np.mean(sims)
                if avg_sim > max_sim:
                    max_sim = avg_sim
                    best_cluster = cluster_id
            labels_all[idx] = best_cluster

        return labels_all

    def fit(self, X):
        # BÆ°á»›c tiá»n xá»­ lÃ½
        X = self.preprocess(X)
        n_samples = X.shape[0]

        # BÆ°á»›c 1: Láº¥y sample ngáº«u nhiÃªn
        sample_size = int(self.sample_ratio * n_samples)
        sample_idx = np.random.choice(n_samples, sample_size, replace=False)
        X_sample = X[sample_idx]

        if self.verbose:
            print(f"ðŸ“¦ Sampled {sample_size}/{n_samples} points.")

        # BÆ°á»›c 2: PhÃ¢n cá»¥m trÃªn sample
        S = self._similarity(X_sample)
        links = (S >= self.theta).astype(int)
        link_matrix = links @ links  # NhÃ¢n ma tráº­n Ä‘á»ƒ Ä‘áº¿m sá»‘ neighbor chung
        clusters = [{i} for i in range(sample_size)]
        max_cluster_size = int(sample_size * self.max_cluster_size_ratio)

        while len(clusters) > self.k:
            best_pair = None
            max_goodness = -np.inf

            # Duyá»‡t táº¥t cáº£ cáº·p cá»¥m Ä‘á»ƒ tÃ¬m cáº·p cÃ³ goodness cao nháº¥t
            for i in range(len(clusters)):
                for j in range(i + 1, len(clusters)):
                    if len(clusters[i]) + len(clusters[j]) > max_cluster_size:
                        continue
                    ci = list(clusters[i])
                    cj = list(clusters[j])
                    goodness = self._calculate_goodness(ci, cj, link_matrix)

                    if goodness > max_goodness and goodness > self.min_goodness:
                        max_goodness = goodness
                        best_pair = (i, j)

            if best_pair is None:
                if self.verbose:
                    print("âš  No more clusters to merge (goodness below threshold).")
                break

            # Gá»™p hai cá»¥m tá»‘t nháº¥t
            i, j = best_pair
            clusters[i].update(clusters[j])
            clusters.pop(j)
            if self.verbose:
                print(f"âœ… Merged cluster {i} and {j} | Total clusters: {len(clusters)}")

        # GÃ¡n nhÃ£n cho sample
        labels_sample = np.zeros(sample_size, dtype=int)
        for idx, cluster in enumerate(clusters):
            for sample in cluster:
                labels_sample[sample] = idx

        if self.verbose:
            print("ðŸŽ¯ Sample clustering complete. Assigning remaining points...")

        # BÆ°á»›c 3: GÃ¡n cÃ¡c Ä‘iá»ƒm cÃ²n láº¡i vÃ o cá»¥m gáº§n nháº¥t
        labels_all = self._assign_remaining_points(X, sample_idx, clusters, labels_sample)

        if self.verbose:
            print("ðŸŽ‰ All points assigned. Clustering complete.")
        return labels_all